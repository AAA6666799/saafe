{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimized Transformer Model\n",
    "\n",
    "### 3.1 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedFireTransformer(nn.Module):\n",
    "    \"\"\"Optimized transformer for multi-area fire detection\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=6, seq_len=60, d_model=128, num_heads=4, \n",
    "                 num_layers=3, num_classes=3, num_areas=5, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.area_embedding = nn.Embedding(num_areas, d_model)\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(seq_len, d_model))\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=num_heads, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, batch_first=True, activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        self.fire_classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model//2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.risk_predictor = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, area_types):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        x = self.input_proj(x)\n",
    "        area_emb = self.area_embedding(area_types).unsqueeze(1).expand(-1, seq_len, -1)\n",
    "        x = x + area_emb + self.pos_encoding[:seq_len].unsqueeze(0)\n",
    "        \n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # Global pooling\n",
    "        \n",
    "        return {\n",
    "            'fire_logits': self.fire_classifier(x),\n",
    "            'risk_score': self.risk_predictor(x) * 100.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Parameter Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_parameters(model):\n",
    "    \"\"\"Visualize model parameters and architecture\"\"\"\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    # Get parameter sizes by layer\n",
    "    layer_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name.split('.')[0]\n",
    "        if layer_name not in layer_params:\n",
    "            layer_params[layer_name] = 0\n",
    "        layer_params[layer_name] += param.numel()\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Parameter count pie chart\n",
    "    labels = list(layer_params.keys())\n",
    "    sizes = list(layer_params.values())\n",
    "    \n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.axis('equal')\n",
    "    ax1.set_title('Parameter Distribution by Layer')\n",
    "    \n",
    "    # Parameter count bar chart\n",
    "    y_pos = np.arange(len(labels))\n",
    "    ax2.barh(y_pos, sizes)\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(labels)\n",
    "    ax2.set_xlabel('Number of Parameters')\n",
    "    ax2.set_title('Parameter Count by Layer')\n",
    "    \n",
    "    # Add parameter count labels\n",
    "    for i, v in enumerate(sizes):\n",
    "        ax2.text(v + 0.1, i, f\"{v:,}\", va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure if enabled\n",
    "    if VISUALIZATION_CONFIG['save_figures']:\n",
    "        plt.savefig(f\"{VISUALIZATION_CONFIG['figure_dir']}/model_parameters.png\", dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"ðŸ“Š Model Parameter Summary:\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Non-trainable parameters: {total_params - trainable_params:,}\")\n",
    "    \n",
    "    # Compare with original model\n",
    "    original_params = 256 * 6 * 4 * 256  # Rough estimate\n",
    "    reduction = 1 - (total_params / original_params)\n",
    "    print(f\"   Parameter reduction: {reduction:.1%} from original model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Dashboard and Visualizations\n",
    "\n",
    "### 4.1 Real-time Training Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_dashboard():\n",
    "    \"\"\"Create a real-time training progress dashboard\"\"\"\n",
    "    \n",
    "    # Initialize dashboard data\n",
    "    dashboard_data = {\n",
    "        'epochs': [],\n",
    "        'train_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'learning_rate': [],\n",
    "        'time_elapsed': [],\n",
    "        'memory_usage': []\n",
    "    }\n",
    "    \n",
    "    # Create initial plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Fire Detection AI - Training Progress Dashboard', fontsize=16)\n",
    "    \n",
    "    # Loss plot\n",
    "    loss_line, = axes[0, 0].plot([], [], 'b-', label='Training Loss')\n",
    "    axes[0, 0].set_title('Training Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    acc_line, = axes[0, 1].plot([], [], 'g-', label='Validation Accuracy')\n",
    "    axes[0, 1].set_title('Validation Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    lr_line, = axes[1, 0].plot([], [], 'r-', label='Learning Rate')\n",
    "    axes[1, 0].set_title('Learning Rate')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Memory usage plot\n",
    "    mem_line, = axes[1, 1].plot([], [], 'm-', label='GPU Memory Usage (GB)')\n",
    "    axes[1, 1].set_title('GPU Memory Usage')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Memory (GB)')\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    return fig, axes, dashboard_data\n",
    "\n",
    "def update_dashboard(fig, axes, dashboard_data, epoch, loss, accuracy, lr, time_elapsed, memory_usage):\n",
    "    \"\"\"Update the training dashboard with new data\"\"\"\n",
    "    \n",
    "    # Update data\n",
    "    dashboard_data['epochs'].append(epoch)\n",
    "    dashboard_data['train_loss'].append(loss)\n",
    "    dashboard_data['val_accuracy'].append(accuracy)\n",
    "    dashboard_data['learning_rate'].append(lr)\n",
    "    dashboard_data['time_elapsed'].append(time_elapsed)\n",
    "    dashboard_data['memory_usage'].append(memory_usage)\n",
    "    \n",
    "    # Update plots\n",
    "    axes[0, 0].plot(dashboard_data['epochs'], dashboard_data['train_loss'], 'b-')\n",
    "    axes[0, 1].plot(dashboard_data['epochs'], dashboard_data['val_accuracy'], 'g-')\n",
    "    axes[1, 0].plot(dashboard_data['epochs'], dashboard_data['learning_rate'], 'r-')\n",
    "    axes[1, 1].plot(dashboard_data['epochs'], dashboard_data['memory_usage'], 'm-')\n",
    "    \n",
    "    # Update limits\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axes[i, j].relim()\n",
    "            axes[i, j].autoscale_view()\n",
    "    \n",
    "    # Add current values as text\n",
    "    plt.figtext(0.5, 0.01, f\"Epoch: {epoch} | Loss: {loss:.4f} | Accuracy: {accuracy:.4f} | Time: {time_elapsed:.1f}s\", \n",
    "                ha=\"center\", fontsize=12, bbox={\"facecolor\":\"orange\", \"alpha\":0.2, \"pad\":5})\n",
    "    \n",
    "    # Refresh the figure\n",
    "    fig.canvas.draw()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(fig)\n",
    "    \n",
    "    # Save figure if enabled\n",
    "    if VISUALIZATION_CONFIG['save_figures']:\n",
    "        plt.savefig(f\"{VISUALIZATION_CONFIG['figure_dir']}/training_dashboard_epoch_{epoch}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Memory Usage Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_memory_usage():\n",
    "    \"\"\"Monitor and visualize memory usage during training\"\"\"\n",
    "    \n",
    "    # Initialize memory tracking\n",
    "    memory_usage = []\n",
    "    timestamps = []\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        # Get initial memory usage\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        initial_memory = torch.cuda.memory_allocated() / 1e9  # GB\n",
    "        \n",
    "        memory_usage.append(initial_memory)\n",
    "        timestamps.append(0)\n",
    "        \n",
    "        def track_memory():\n",
    "            current_memory = torch.cuda.memory_allocated() / 1e9  # GB\n",
    "            peak_memory = torch.cuda.max_memory_allocated() / 1e9  # GB\n",
    "            memory_usage.append(current_memory)\n",
    "            timestamps.append(time.time() - start_time)\n",
    "            \n",
    "            return current_memory, peak_memory\n",
    "    else:\n",
    "        # CPU memory tracking (psutil)\n",
    "        try:\n",
    "            import psutil\n",
    "            process = psutil.Process(os.getpid())\n",
    "            initial_memory = process.memory_info().rss / 1e9  # GB\n",
    "            \n",
    "            memory_usage.append(initial_memory)\n",
    "            timestamps.append(0)\n",
    "            \n",
    "            def track_memory():\n",
    "                current_memory = process.memory_info().rss / 1e9  # GB\n",
    "                memory_usage.append(current_memory)\n",
    "                timestamps.append(time.time() - start_time)\n",
    "                \n",
    "                return current_memory, max(memory_usage)\n",
    "        except ImportError:\n",
    "            # Fallback if psutil not available\n",
    "            def track_memory():\n",
    "                return 0, 0\n",
    "    \n",
    "    return track_memory, memory_usage, timestamps\n",
    "\n",
    "def visualize_memory_usage(memory_usage, timestamps):\n",
    "    \"\"\"Visualize memory usage during training\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(timestamps, memory_usage, 'b-')\n",
    "    plt.title('Memory Usage During Training')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Memory Usage (GB)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add peak memory as text\n",
    "    peak_memory = max(memory_usage)\n",
    "    plt.axhline(y=peak_memory, color='r', linestyle='--', label=f'Peak: {peak_memory:.2f} GB')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save figure if enabled\n",
    "    if VISUALIZATION_CONFIG['save_figures']:\n",
    "        plt.savefig(f\"{VISUALIZATION_CONFIG['figure_dir']}/memory_usage.png\", dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Initialize Model and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"ðŸš€ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Initialize model\n",
    "model = OptimizedFireTransformer(\n",
    "    input_dim=X_train.shape[2],\n",
    "    seq_len=X_train.shape[1],\n",
    "    d_model=TRANSFORMER_CONFIG['d_model'],\n",
    "    num_heads=TRANSFORMER_CONFIG['num_heads'],\n",
    "    num_layers=TRANSFORMER_CONFIG['num_layers'],\n",
    "    num_classes=len(np.unique(y_train)),\n",
    "    num_areas=len(np.unique(areas_train)),\n",
    "    dropout=TRANSFORMER_CONFIG['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Visualize model parameters\n",
    "visualize_model_parameters(model)\n",
    "\n",
    "# Initialize training dashboard\n",
    "dashboard_fig, dashboard_axes, dashboard_data = create_training_dashboard()\n",
    "\n",
    "# Initialize memory tracking\n",
    "track_memory, memory_usage, timestamps = monitor_memory_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}