{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoT-based Predictive Fire Detection Training\n",
    "Training Spatio-Temporal Transformer models for multi-area fire prediction with lead time classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision pandas numpy matplotlib seaborn scikit-learn boto3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "INPUT_BUCKET = \"synthetic-data-4\"\n",
    "OUTPUT_BUCKET = \"processedd-synthetic-data\"\n",
    "REGION = \"us-east-1\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"🔥 IoT Fire Detection Training\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Input: s3://{INPUT_BUCKET}/datasets/\")\n",
    "print(f\"Output: s3://{OUTPUT_BUCKET}/fire-models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration for IoT Fire Detection\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for IoT-based Predictive Fire Detection Transformer\"\"\"\n",
    "    d_model: int = 256\n",
    "    num_heads: int = 8\n",
    "    num_layers: int = 6\n",
    "    max_seq_length: int = 60  # 1 minute of data at 1Hz\n",
    "    dropout: float = 0.1\n",
    "    num_risk_levels: int = 4  # immediate, hours, days, weeks\n",
    "    \n",
    "    # Area-specific sensor configuration\n",
    "    areas = {\n",
    "        'kitchen': {\n",
    "            'sensor_type': 'voc_ml',\n",
    "            'features': ['voc_level'],\n",
    "            'feature_dim': 1,\n",
    "            'lead_time_range': 'minutes_hours',\n",
    "            'vendor': 'honeywell_mics'\n",
    "        },\n",
    "        'electrical': {\n",
    "            'sensor_type': 'arc_detection', \n",
    "            'features': ['arc_count'],\n",
    "            'feature_dim': 1,\n",
    "            'lead_time_range': 'days_weeks',\n",
    "            'vendor': 'ting_eaton'\n",
    "        },\n",
    "        'laundry_hvac': {\n",
    "            'sensor_type': 'thermal_current',\n",
    "            'features': ['temperature', 'current'],\n",
    "            'feature_dim': 2,\n",
    "            'lead_time_range': 'hours_days', \n",
    "            'vendor': 'honeywell_thermal'\n",
    "        },\n",
    "        'living_bedroom': {\n",
    "            'sensor_type': 'aspirating_smoke',\n",
    "            'features': ['particle_level'],\n",
    "            'feature_dim': 1,\n",
    "            'lead_time_range': 'minutes_hours',\n",
    "            'vendor': 'xtralis_vesda'\n",
    "        },\n",
    "        'basement_storage': {\n",
    "            'sensor_type': 'environmental_iot',\n",
    "            'features': ['temperature', 'humidity', 'gas_levels'],\n",
    "            'feature_dim': 3,\n",
    "            'lead_time_range': 'hours_days',\n",
    "            'vendor': 'bosch_airthings'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    @property\n",
    "    def num_areas(self):\n",
    "        return len(self.areas)\n",
    "    \n",
    "    @property\n",
    "    def total_feature_dim(self):\n",
    "        return sum(area['feature_dim'] for area in self.areas.values())\n",
    "\n",
    "config = ModelConfig()\n",
    "print(f\"Model Config: {config.num_areas} areas, {config.total_feature_dim} total features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Fire Detection Transformer Model\n",
    "class FireDetectionTransformer(nn.Module):\n",
    "    \"\"\"Simplified Spatio-Temporal Transformer for Fire Detection\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Area-specific input embeddings\n",
    "        self.area_embeddings = nn.ModuleDict()\n",
    "        for area_name, area_config in config.areas.items():\n",
    "            self.area_embeddings[area_name] = nn.Linear(area_config['feature_dim'], config.d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(config.max_seq_length, config.d_model))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.d_model,\n",
    "            nhead=config.num_heads,\n",
    "            dim_feedforward=config.d_model * 4,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=config.num_layers)\n",
    "        \n",
    "        # Output heads\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Lead time classification (immediate=0, hours=1, days=2, weeks=3)\n",
    "        self.lead_time_classifier = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_model // 2, config.num_risk_levels)\n",
    "        )\n",
    "        \n",
    "        # Fire probability (0-1)\n",
    "        self.fire_probability = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_model // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Time to ignition (hours)\n",
    "        self.time_to_ignition = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_model // 2, 1),\n",
    "            nn.ReLU()  # Positive values only\n",
    "        )\n",
    "    \n",
    "    def forward(self, area_data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Forward pass for fire detection\"\"\"\n",
    "        batch_size = next(iter(area_data.values())).shape[0]\n",
    "        seq_len = next(iter(area_data.values())).shape[1]\n",
    "        \n",
    "        # Process each area's data\n",
    "        area_embeddings = []\n",
    "        for area_name in self.config.areas.keys():\n",
    "            if area_name in area_data:\n",
    "                area_tensor = area_data[area_name]  # (batch, seq_len, features)\n",
    "                embedded = self.area_embeddings[area_name](area_tensor)  # (batch, seq_len, d_model)\n",
    "                area_embeddings.append(embedded)\n",
    "            else:\n",
    "                # Handle missing area with zeros\n",
    "                feature_dim = self.config.areas[area_name]['feature_dim']\n",
    "                zero_data = torch.zeros(batch_size, seq_len, feature_dim, device=next(iter(area_data.values())).device)\n",
    "                embedded = self.area_embeddings[area_name](zero_data)\n",
    "                area_embeddings.append(embedded)\n",
    "        \n",
    "        # Combine all areas: (batch, seq_len, num_areas * d_model)\n",
    "        combined = torch.cat(area_embeddings, dim=-1)\n",
    "        \n",
    "        # Project to d_model dimension\n",
    "        combined = nn.Linear(combined.shape[-1], self.config.d_model).to(combined.device)(combined)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        combined = combined + self.pos_encoding[:seq_len].unsqueeze(0)\n",
    "        \n",
    "        # Apply transformer\n",
    "        transformer_out = self.transformer(combined)  # (batch, seq_len, d_model)\n",
    "        \n",
    "        # Global pooling\n",
    "        pooled = self.global_pool(transformer_out.transpose(1, 2)).squeeze(-1)  # (batch, d_model)\n",
    "        \n",
    "        # Predictions\n",
    "        lead_time_logits = self.lead_time_classifier(pooled)\n",
    "        fire_prob = self.fire_probability(pooled)\n",
    "        time_to_ignition = self.time_to_ignition(pooled)\n",
    "        \n",
    "        return {\n",
    "            'lead_time_logits': lead_time_logits,\n",
    "            'fire_probability': fire_prob,\n",
    "            'time_to_ignition': time_to_ignition,\n",
    "            'features': pooled\n",
    "        }\n",
    "\n",
    "# Create model\n",
    "model = FireDetectionTransformer(config).to(DEVICE)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_fire_data(dataset_name, area_name, sample_size=50000):\n",
    "    \"\"\"Load and prepare fire detection data from S3\"\"\"\n",
    "    print(f\"Loading {dataset_name} for {area_name}...\")\n",
    "    \n",
    "    # Load data from S3\n",
    "    df = pd.read_csv(f\"s3://{INPUT_BUCKET}/datasets/{dataset_name}\")\n",
    "    \n",
    "    # Sample data for faster training\n",
    "    if len(df) > sample_size:\n",
    "        df = df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Loaded {len(df):,} samples\")\n",
    "    print(f\"Anomaly rate: {df['is_anomaly'].mean():.4f}\")\n",
    "    \n",
    "    # Convert timestamp\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Create sequences\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    lead_times = []\n",
    "    \n",
    "    seq_len = config.max_seq_length\n",
    "    \n",
    "    for i in range(len(df) - seq_len):\n",
    "        # Get sequence\n",
    "        seq_data = df.iloc[i:i+seq_len]\n",
    "        \n",
    "        # Prepare features based on area type\n",
    "        if area_name == 'kitchen':  # VOC data\n",
    "            features = seq_data[['value']].values\n",
    "        elif area_name == 'electrical':  # Arc data\n",
    "            features = seq_data[['value']].values\n",
    "        elif area_name == 'laundry_hvac':  # Thermal + current (simulate)\n",
    "            features = np.column_stack([\n",
    "                seq_data['value'].values,\n",
    "                seq_data['value'].values * 0.1 + np.random.normal(0, 0.01, len(seq_data))  # Simulated current\n",
    "            ])\n",
    "        elif area_name == 'living_bedroom':  # Aspirating smoke\n",
    "            features = seq_data[['value']].values\n",
    "        elif area_name == 'basement_storage':  # Environmental IoT\n",
    "            features = np.column_stack([\n",
    "                seq_data['value'].values,  # Temperature\n",
    "                seq_data['value'].values * 0.5 + 50,  # Humidity\n",
    "                seq_data['value'].values * 0.01  # Gas levels\n",
    "            ])\n",
    "        \n",
    "        sequences.append(features)\n",
    "        \n",
    "        # Label (fire probability)\n",
    "        is_fire = seq_data['is_anomaly'].iloc[-1]  # Use last value as label\n",
    "        labels.append(float(is_fire))\n",
    "        \n",
    "        # Lead time classification (simulate based on anomaly strength)\n",
    "        if is_fire:\n",
    "            # Simulate lead time based on sensor type\n",
    "            if area_name in ['kitchen', 'living_bedroom']:  # Fast detection\n",
    "                lead_time = np.random.choice([0, 1], p=[0.7, 0.3])  # immediate or hours\n",
    "            elif area_name == 'laundry_hvac':\n",
    "                lead_time = np.random.choice([1, 2], p=[0.6, 0.4])  # hours or days\n",
    "            elif area_name == 'electrical':\n",
    "                lead_time = np.random.choice([2, 3], p=[0.5, 0.5])  # days or weeks\n",
    "            else:\n",
    "                lead_time = np.random.choice([1, 2], p=[0.5, 0.5])  # hours or days\n",
    "        else:\n",
    "            lead_time = 3  # No fire = weeks (safe)\n",
    "        \n",
    "        lead_times.append(lead_time)\n",
    "    \n",
    "    return np.array(sequences), np.array(labels), np.array(lead_times)\n",
    "\n",
    "# Load data for all areas\n",
    "area_datasets = {\n",
    "    'kitchen': 'voc_data.csv',\n",
    "    'electrical': 'arc_data.csv', \n",
    "    'laundry_hvac': 'laundry_data.csv',\n",
    "    'living_bedroom': 'asd_data.csv',\n",
    "    'basement_storage': 'basement_data.csv'\n",
    "}\n",
    "\n",
    "area_data = {}\n",
    "for area_name, dataset_file in area_datasets.items():\n",
    "    sequences, labels, lead_times = load_and_prepare_fire_data(dataset_file, area_name, sample_size=10000)\n",
    "    area_data[area_name] = {\n",
    "        'sequences': torch.FloatTensor(sequences),\n",
    "        'labels': torch.FloatTensor(labels),\n",
    "        'lead_times': torch.LongTensor(lead_times)\n",
    "    }\n",
    "    print(f\"{area_name}: {sequences.shape} sequences\")\n",
    "\n",
    "print(f\"\\nTotal areas loaded: {len(area_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "class FireDetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, area_data, config):\n",
    "        self.area_data = area_data\n",
    "        self.config = config\n",
    "        \n",
    "        # Use the minimum length across all areas\n",
    "        self.length = min(len(data['sequences']) for data in area_data.values())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_area_data = {}\n",
    "        \n",
    "        # Get data for each area\n",
    "        for area_name in self.config.areas.keys():\n",
    "            if area_name in self.area_data:\n",
    "                batch_area_data[area_name] = self.area_data[area_name]['sequences'][idx]\n",
    "        \n",
    "        # Use first area's labels (they should be similar across areas for same time)\n",
    "        first_area = next(iter(self.area_data.keys()))\n",
    "        fire_label = self.area_data[first_area]['labels'][idx]\n",
    "        lead_time_label = self.area_data[first_area]['lead_times'][idx]\n",
    "        \n",
    "        return batch_area_data, fire_label, lead_time_label\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = FireDetectionDataset(area_data, config)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Validation samples: {len(val_dataset):,}\")\n",
    "print(f\"Batch size: 32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "# Loss functions\n",
    "fire_criterion = nn.BCELoss()  # Fire probability\n",
    "lead_time_criterion = nn.CrossEntropyLoss()  # Lead time classification\n",
    "time_criterion = nn.MSELoss()  # Time to ignition\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    fire_losses = []\n",
    "    lead_time_losses = []\n",
    "    \n",
    "    for batch_idx, (area_batch, fire_labels, lead_time_labels) in enumerate(train_loader):\n",
    "        # Move to device\n",
    "        area_batch = {k: v.to(DEVICE) for k, v in area_batch.items()}\n",
    "        fire_labels = fire_labels.to(DEVICE)\n",
    "        lead_time_labels = lead_time_labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(area_batch)\n",
    "        \n",
    "        # Compute losses\n",
    "        fire_loss = fire_criterion(outputs['fire_probability'].squeeze(), fire_labels)\n",
    "        lead_time_loss = lead_time_criterion(outputs['lead_time_logits'], lead_time_labels)\n",
    "        \n",
    "        # Simulate time to ignition (hours)\n",
    "        time_targets = torch.where(fire_labels > 0.5, \n",
    "                                 torch.rand_like(fire_labels) * 24,  # 0-24 hours for fire\n",
    "                                 torch.ones_like(fire_labels) * 168)  # 1 week for no fire\n",
    "        time_loss = time_criterion(outputs['time_to_ignition'].squeeze(), time_targets)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_batch_loss = fire_loss + lead_time_loss + 0.1 * time_loss\n",
    "        \n",
    "        total_batch_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += total_batch_loss.item()\n",
    "        fire_losses.append(fire_loss.item())\n",
    "        lead_time_losses.append(lead_time_loss.item())\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Batch {batch_idx:3d}: Fire Loss: {fire_loss.item():.4f}, Lead Time Loss: {lead_time_loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(train_loader), np.mean(fire_losses), np.mean(lead_time_losses)\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    fire_preds = []\n",
    "    fire_targets = []\n",
    "    lead_time_preds = []\n",
    "    lead_time_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for area_batch, fire_labels, lead_time_labels in val_loader:\n",
    "            area_batch = {k: v.to(DEVICE) for k, v in area_batch.items()}\n",
    "            fire_labels = fire_labels.to(DEVICE)\n",
    "            lead_time_labels = lead_time_labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(area_batch)\n",
    "            \n",
    "            # Losses\n",
    "            fire_loss = fire_criterion(outputs['fire_probability'].squeeze(), fire_labels)\n",
    "            lead_time_loss = lead_time_criterion(outputs['lead_time_logits'], lead_time_labels)\n",
    "            \n",
    "            time_targets = torch.where(fire_labels > 0.5, \n",
    "                                     torch.rand_like(fire_labels) * 24,\n",
    "                                     torch.ones_like(fire_labels) * 168)\n",
    "            time_loss = time_criterion(outputs['time_to_ignition'].squeeze(), time_targets)\n",
    "            \n",
    "            total_loss += (fire_loss + lead_time_loss + 0.1 * time_loss).item()\n",
    "            \n",
    "            # Collect predictions\n",
    "            fire_preds.extend(outputs['fire_probability'].cpu().numpy())\n",
    "            fire_targets.extend(fire_labels.cpu().numpy())\n",
    "            lead_time_preds.extend(torch.argmax(outputs['lead_time_logits'], dim=1).cpu().numpy())\n",
    "            lead_time_targets.extend(lead_time_labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fire_preds = np.array(fire_preds)\n",
    "    fire_targets = np.array(fire_targets)\n",
    "    \n",
    "    fire_auc = roc_auc_score(fire_targets, fire_preds)\n",
    "    fire_accuracy = ((fire_preds > 0.5) == fire_targets).mean()\n",
    "    \n",
    "    lead_time_accuracy = (np.array(lead_time_preds) == np.array(lead_time_targets)).mean()\n",
    "    \n",
    "    return total_loss / len(val_loader), fire_auc, fire_accuracy, lead_time_accuracy\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "fire_aucs = []\n",
    "fire_accuracies = []\n",
    "lead_time_accuracies = []\n",
    "\n",
    "print(f\"🔥 Starting Fire Detection Training for {num_epochs} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Training\n",
    "    train_loss, fire_loss, lead_time_loss = train_epoch(model, train_loader, optimizer)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, fire_auc, fire_acc, lead_time_acc = validate_epoch(model, val_loader)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    fire_aucs.append(fire_auc)\n",
    "    fire_accuracies.append(fire_acc)\n",
    "    lead_time_accuracies.append(lead_time_acc)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Fire AUC: {fire_auc:.4f}\")\n",
    "    print(f\"Fire Accuracy: {fire_acc:.4f}\")\n",
    "    print(f\"Lead Time Accuracy: {lead_time_acc:.4f}\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'config': config,\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'fire_auc': fire_auc,\n",
    "            'fire_accuracy': fire_acc,\n",
    "            'lead_time_accuracy': lead_time_acc\n",
    "        }, '/tmp/best_fire_model.pth')\n",
    "        print(\"💾 Saved best model!\")\n",
    "\n",
    "print(\"\\n🎉 Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('🔥 Fire Detection Training Results', fontsize=16)\n",
    "\n",
    "# Training/Validation Loss\n",
    "axes[0, 0].plot(train_losses, label='Training Loss', color='blue')\n",
    "axes[0, 0].plot(val_losses, label='Validation Loss', color='red')\n",
    "axes[0, 0].set_title('Training & Validation Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Fire Detection AUC\n",
    "axes[0, 1].plot(fire_aucs, label='Fire Detection AUC', color='orange')\n",
    "axes[0, 1].set_title('Fire Detection AUC Score')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('AUC Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Fire Detection Accuracy\n",
    "axes[1, 0].plot(fire_accuracies, label='Fire Accuracy', color='green')\n",
    "axes[1, 0].set_title('Fire Detection Accuracy')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Lead Time Classification Accuracy\n",
    "axes[1, 1].plot(lead_time_accuracies, label='Lead Time Accuracy', color='purple')\n",
    "axes[1, 1].set_title('Lead Time Classification Accuracy')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\n🏆 FINAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "print(f\"Final Fire AUC: {fire_aucs[-1]:.4f}\")\n",
    "print(f\"Final Fire Accuracy: {fire_accuracies[-1]:.4f}\")\n",
    "print(f\"Final Lead Time Accuracy: {lead_time_accuracies[-1]:.4f}\")\n",
    "print(f\"Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and results to S3\n",
    "s3_client = boto3.client('s3', region_name=REGION)\n",
    "\n",
    "# Save model\n",
    "model_key = f\"fire-models/iot_fire_transformer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth\"\n",
    "s3_client.upload_file('/tmp/best_fire_model.pth', OUTPUT_BUCKET, model_key)\n",
    "print(f\"🚀 Model saved to s3://{OUTPUT_BUCKET}/{model_key}\")\n",
    "\n",
    "# Save training metrics\n",
    "training_results = {\n",
    "    'training_timestamp': datetime.now().isoformat(),\n",
    "    'model_type': 'IoT_Fire_Detection_Transformer',\n",
    "    'num_epochs': num_epochs,\n",
    "    'best_val_loss': float(best_val_loss),\n",
    "    'final_fire_auc': float(fire_aucs[-1]),\n",
    "    'final_fire_accuracy': float(fire_accuracies[-1]),\n",
    "    'final_lead_time_accuracy': float(lead_time_accuracies[-1]),\n",
    "    'model_parameters': sum(p.numel() for p in model.parameters()),\n",
    "    'config': {\n",
    "        'd_model': config.d_model,\n",
    "        'num_heads': config.num_heads,\n",
    "        'num_layers': config.num_layers,\n",
    "        'num_areas': config.num_areas,\n",
    "        'total_features': config.total_feature_dim\n",
    "    },\n",
    "    'areas_trained': list(config.areas.keys()),\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'fire_aucs': fire_aucs,\n",
    "        'fire_accuracies': fire_accuracies,\n",
    "        'lead_time_accuracies': lead_time_accuracies\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results JSON\n",
    "results_json = json.dumps(training_results, indent=2)\n",
    "with open('/tmp/training_results.json', 'w') as f:\n",
    "    f.write(results_json)\n",
    "\n",
    "results_key = f\"fire-models/training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "s3_client.upload_file('/tmp/training_results.json', OUTPUT_BUCKET, results_key)\n",
    "print(f\"📊 Results saved to s3://{OUTPUT_BUCKET}/{results_key}\")\n",
    "\n",
    "# Save training plot\n",
    "plt.savefig('/tmp/training_plot.png', dpi=300, bbox_inches='tight')\n",
    "plot_key = f\"fire-models/training_plot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "s3_client.upload_file('/tmp/training_plot.png', OUTPUT_BUCKET, plot_key)\n",
    "print(f\"📈 Plot saved to s3://{OUTPUT_BUCKET}/{plot_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference with sample data\n",
    "print(\"\\n🧪 TESTING INFERENCE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Create sample test data\n",
    "    test_data = {}\n",
    "    for area_name, area_config in config.areas.items():\n",
    "        feature_dim = area_config['feature_dim']\n",
    "        # Simulate normal readings\n",
    "        test_data[area_name] = torch.randn(1, config.max_seq_length, feature_dim).to(DEVICE)\n",
    "    \n",
    "    # Get predictions\n",
    "    outputs = model(test_data)\n",
    "    \n",
    "    # Interpret results\n",
    "    fire_prob = outputs['fire_probability'].item()\n",
    "    lead_time_pred = torch.argmax(outputs['lead_time_logits'], dim=1).item()\n",
    "    time_to_ignition = outputs['time_to_ignition'].item()\n",
    "    \n",
    "    lead_time_labels = ['Immediate (<1h)', 'Hours (1-24h)', 'Days (1-7d)', 'Weeks (>7d)']\n",
    "    \n",
    "    print(f\"🔥 Fire Probability: {fire_prob:.4f} ({fire_prob*100:.1f}%)\")\n",
    "    print(f\"⏰ Lead Time Category: {lead_time_labels[lead_time_pred]}\")\n",
    "    print(f\"🕐 Time to Ignition: {time_to_ignition:.1f} hours\")\n",
    "    \n",
    "    if fire_prob > 0.5:\n",
    "        print(\"\\n🚨 FIRE RISK DETECTED!\")\n",
    "    else:\n",
    "        print(\"\\n✅ Normal conditions\")\n",
    "\n",
    "print(\"\\n🎉 Fire Detection Model Training Complete!\")\n",
    "print(f\"📁 All artifacts saved to s3://{OUTPUT_BUCKET}/fire-models/\")\n",
    "print(\"\\n🚀 Your IoT Fire Detection System is ready for deployment!\")"
   ]
  }
 ],
 "metadata": {\n",
  \"kernelspec\": {\n",
   \"display_name\": \"Python 3\",\n",
   \"language\": \"python\",\n",
   \"name\": \"python3\"\n",
  },\n",
  \"language_info\": {\n",
   \"codemirror_mode\": {\n",
    \"name\": \"ipython\",\n",
    \"version\": 3\n",
   },\n",
   \"file_extension\": \".py\",\n",
   \"mimetype\": \"text/x-python\",\n",
   \"name\": \"python\",\n",
   \"nbconvert_exporter\": \"python\",\n",
   \"pygments_lexer\": \"ipython3\",\n",
   \"version\": \"3.8.5\"\n",
  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}