#!/usr/bin/env python3
"""
Simple, environment-safe training launcher for Saafe.
Bypasses conda/pip conflicts and gets straight to training.
"""

import os
import sys
import subprocess
import json
import time
from datetime import datetime

def print_banner():
    """Print startup banner."""
    print("üöÄ SAAFE ULTRA-FAST TRAINING")
    print("=" * 40)
    print("üí∞ Cost: $6-12")
    print("‚ö° Time: 30-45 minutes")
    print("üî• 4x NVIDIA V100 GPUs")
    print()

def check_aws():
    """Check AWS CLI and credentials."""
    print("üîç Checking AWS setup...")
    
    try:
        # Check AWS CLI
        result = subprocess.run(['aws', '--version'], capture_output=True, text=True)
        if result.returncode != 0:
            print("‚ùå AWS CLI not found")
            print("Install: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html")
            return False
        
        # Check credentials
        result = subprocess.run(['aws', 'sts', 'get-caller-identity'], capture_output=True, text=True)
        if result.returncode != 0:
            print("‚ùå AWS credentials not configured")
            print("Run: aws configure")
            return False
        
        # Get account info
        account_data = json.loads(result.stdout)
        account_id = account_data['Account']
        
        # Get region
        result = subprocess.run(['aws', 'configure', 'get', 'region'], capture_output=True, text=True)
        region = result.stdout.strip() or 'us-east-1'
        
        print(f"‚úÖ AWS configured")
        print(f"   Account: {account_id}")
        print(f"   Region: {region}")
        return True
        
    except Exception as e:
        print(f"‚ùå AWS check failed: {e}")
        return False

def install_deps():
    """Install minimal dependencies safely."""
    print("üì¶ Installing dependencies...")
    
    # Use system python to avoid conda issues
    deps = ['boto3', 'sagemaker']
    
    for dep in deps:
        try:
            __import__(dep)
            print(f"   ‚úÖ {dep} already available")
        except ImportError:
            print(f"   üì• Installing {dep}...")
            try:
                subprocess.run([sys.executable, '-m', 'pip', 'install', '--user', dep], 
                             check=True, capture_output=True)
                print(f"   ‚úÖ {dep} installed")
            except subprocess.CalledProcessError:
                print(f"   ‚ö†Ô∏è  {dep} install failed (may still work)")
    
    print("‚úÖ Dependencies ready")

def create_role():
    """Create SageMaker role."""
    print("üîê Setting up SageMaker role...")
    
    role_name = "SaafeTrainingRole"
    
    # Check if exists
    try:
        result = subprocess.run(['aws', 'iam', 'get-role', '--role-name', role_name], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ SageMaker role exists")
            return True
    except:
        pass
    
    print("   Creating role...")
    
    # Trust policy
    trust_policy = {
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {"Service": "sagemaker.amazonaws.com"},
            "Action": "sts:AssumeRole"
        }]
    }
    
    with open('trust.json', 'w') as f:
        json.dump(trust_policy, f)
    
    try:
        # Create role
        subprocess.run(['aws', 'iam', 'create-role', 
                       '--role-name', role_name,
                       '--assume-role-policy-document', 'file://trust.json'], 
                      check=True, capture_output=True)
        
        # Attach policies
        policies = [
            'arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',
            'arn:aws:iam::aws:policy/AmazonS3FullAccess'
        ]
        
        for policy in policies:
            subprocess.run(['aws', 'iam', 'attach-role-policy',
                           '--role-name', role_name,
                           '--policy-arn', policy], 
                          check=True, capture_output=True)
        
        os.remove('trust.json')
        print("‚úÖ SageMaker role created")
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Role setup issue: {e}")
        return True  # Continue anyway

def create_training_script():
    """Create the actual training script."""
    print("üìù Creating training script...")
    
    script_content = '''
import boto3
import sagemaker
from sagemaker.pytorch import PyTorch
import time
import json
from datetime import datetime

def main():
    print("üöÄ Starting SageMaker training job...")
    
    # Get session and role
    session = boto3.Session()
    sagemaker_session = sagemaker.Session(boto_session=session)
    
    # Get account ID for role ARN
    sts = session.client('sts')
    account_id = sts.get_caller_identity()['Account']
    role_arn = f"arn:aws:iam::{account_id}:role/SaafeTrainingRole"
    
    print(f"Using role: {role_arn}")
    
    # Create training code
    training_code = """
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import json
import os
import argparse
from datetime import datetime

class FastFireModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(240, 128),  # 60 timesteps * 4 features
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
        self.classifier = nn.Linear(64, 3)  # normal, cooking, fire
        self.risk_regressor = nn.Sequential(
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # Flatten input: (batch, 60, 4, 4) -> (batch, 240)
        x = x.view(x.size(0), -1)
        features = self.encoder(x)
        
        logits = self.classifier(features)
        risk_score = self.risk_regressor(features) * 100
        
        return {'logits': logits, 'risk_score': risk_score}

def generate_data(num_samples=5000):
    data = torch.randn(num_samples, 60, 4, 4)  # Random sensor data
    
    # Create labels
    labels = torch.randint(0, 3, (num_samples,))
    risks = torch.where(labels == 0, torch.rand(num_samples) * 20,  # normal: 0-20
                       torch.where(labels == 1, 20 + torch.rand(num_samples) * 40,  # cooking: 20-60
                                  80 + torch.rand(num_samples) * 20))  # fire: 80-100
    
    return data, labels, risks

def train_model(args):
    print("üî• Ultra-fast training starting...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # Create model
    model = FastFireModel().to(device)
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # Generate data
    data, labels, risks = generate_data(5000)
    
    # Create data loader
    dataset = torch.utils.data.TensorDataset(data, labels, risks)
    loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)
    
    # Optimizer
    optimizer = optim.AdamW(model.parameters(), lr=0.001)
    
    # Loss functions
    class_loss_fn = nn.CrossEntropyLoss()
    risk_loss_fn = nn.MSELoss()
    
    # Training loop
    model.train()
    for epoch in range(20):  # Fast training
        total_loss = 0
        for batch_data, batch_labels, batch_risks in loader:
            batch_data = batch_data.to(device)
            batch_labels = batch_labels.to(device)
            batch_risks = batch_risks.to(device).unsqueeze(1)
            
            optimizer.zero_grad()
            outputs = model(batch_data)
            
            class_loss = class_loss_fn(outputs['logits'], batch_labels)
            risk_loss = risk_loss_fn(outputs['risk_score'], batch_risks)
            loss = class_loss + risk_loss
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        if (epoch + 1) % 5 == 0:
            print(f"Epoch {epoch+1}/20: Loss = {total_loss/len(loader):.4f}")
    
    # Evaluate
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for batch_data, batch_labels, _ in loader:
            batch_data = batch_data.to(device)
            batch_labels = batch_labels.to(device)
            
            outputs = model(batch_data)
            predicted = torch.argmax(outputs['logits'], dim=1)
            total += batch_labels.size(0)
            correct += (predicted == batch_labels).sum().item()
    
    accuracy = correct / total
    print(f"Final accuracy: {accuracy:.3f}")
    
    # Save model
    torch.save({
        'model_state_dict': model.state_dict(),
        'accuracy': accuracy,
        'training_completed': datetime.now().isoformat()
    }, os.path.join(args.model_dir, 'model.pth'))
    
    # Save metrics
    metrics = {
        'accuracy': accuracy,
        'model_parameters': sum(p.numel() for p in model.parameters()),
        'training_time': '20_epochs',
        'device': str(device)
    }
    
    with open(os.path.join(args.model_dir, 'metrics.json'), 'w') as f:
        json.dump(metrics, f, indent=2)
    
    print("‚úÖ Training completed!")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))
    args = parser.parse_args()
    train_model(args)
"""
    
    # Save training script
    with open('train.py', 'w') as f:
        f.write(training_code)
    
    # Create requirements
    with open('requirements.txt', 'w') as f:
        f.write('torch>=1.12.0\\nnumpy>=1.21.0\\n')
    
    # Create source archive
    import tarfile
    with tarfile.open('source.tar.gz', 'w:gz') as tar:
        tar.add('train.py')
        tar.add('requirements.txt')
    
    # Upload to S3
    s3 = session.client('s3')
    bucket_name = f"saafe-training-{int(time.time())}"
    
    try:
        s3.create_bucket(Bucket=bucket_name)
    except:
        bucket_name = f"saafe-training-{int(time.time())}-{hash(str(time.time())) % 10000}"
        s3.create_bucket(Bucket=bucket_name)
    
    s3.upload_file('source.tar.gz', bucket_name, 'source.tar.gz')
    source_uri = f's3://{bucket_name}/source.tar.gz'
    
    print(f"Training code uploaded to: {source_uri}")
    
    # Create estimator
    estimator = PyTorch(
        entry_point='train.py',
        source_dir=source_uri,
        role=role_arn,
        instance_type='ml.p3.8xlarge',  # 4x V100 GPUs
        instance_count=1,
        framework_version='1.12.0',
        py_version='py38',
        max_run=3600,  # 1 hour max
        output_path=f's3://{bucket_name}/output/',
        sagemaker_session=sagemaker_session
    )
    
    # Launch training
    job_name = f"saafe-ultrafast-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
    print(f"üöÄ Launching job: {job_name}")
    
    estimator.fit(job_name=job_name, wait=False)
    
    print("‚úÖ Training job launched!")
    print(f"Job name: {job_name}")
    print("Monitor: https://console.aws.amazon.com/sagemaker/")
    
    # Clean up local files
    import os
    for f in ['train.py', 'requirements.txt', 'source.tar.gz']:
        if os.path.exists(f):
            os.remove(f)
    
    return job_name

if __name__ == "__main__":
    main()
'''
    
    with open('sagemaker_launcher.py', 'w') as f:
        f.write(script_content)
    
    print("‚úÖ Training script created")

def launch_training():
    """Launch the training job."""
    print("üöÄ Launching ultra-fast training...")
    
    try:
        result = subprocess.run([sys.executable, 'sagemaker_launcher.py'], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print("‚úÖ Training launched successfully!")
            print(result.stdout)
            return True
        else:
            print("‚ùå Training launch failed:")
            print(result.stderr)
            return False
            
    except subprocess.TimeoutExpired:
        print("‚è≥ Training launch taking longer than expected...")
        print("Check AWS Console: https://console.aws.amazon.com/sagemaker/")
        return True
    except Exception as e:
        print(f"‚ùå Launch error: {e}")
        return False

def main():
    """Main function."""
    print_banner()
    
    # Step 1: Check AWS
    if not check_aws():
        return
    
    # Step 2: Install dependencies
    install_deps()
    
    # Step 3: Create role
    create_role()
    
    # Step 4: Create training script
    create_training_script()
    
    # Step 5: Confirm launch
    print("\nüî• READY TO LAUNCH ULTRA-FAST TRAINING")
    print("=" * 45)
    print("Instance: ml.p3.8xlarge (4x NVIDIA V100)")
    print("Cost: ~$12.24/hour")
    print("Expected time: 30-45 minutes")
    print("Expected total: $6-12")
    print()
    
    confirm = input("Launch now? (y/N): ").strip().lower()
    if confirm != 'y':
        print("üëç Cancelled")
        return
    
    # Step 6: Launch
    if launch_training():
        print("\nüéâ SUCCESS!")
        print("=" * 20)
        print("‚úÖ Ultra-fast training launched")
        print("‚è±Ô∏è  Expected completion: 30-45 minutes")
        print("üí∞ Expected cost: $6-12")
        print("üîç Monitor: https://console.aws.amazon.com/sagemaker/")
        print("\nüöÄ Your models will be ready soon!")
    
    # Cleanup
    if os.path.exists('sagemaker_launcher.py'):
        os.remove('sagemaker_launcher.py')

if __name__ == "__main__":
    main()