#!/usr/bin/env python3
"""
Fixed AWS GPU Training for IoT-based Predictive Fire Detection System.
Simplified and more robust version.
"""

import subprocess
import sys
import json
import os
import time
import boto3
from pathlib import Path
from datetime import datetime

def print_banner():
    """Print the IoT training banner."""
    print("üî•" * 60)
    print("üöÄ SAAFE IoT PREDICTIVE FIRE DETECTION TRAINING (FIXED) üöÄ")
    print("üî•" * 60)
    print("üí∞ COST: $8-15 (HIGH PERFORMANCE GPU TRAINING)")
    print("‚ö° TIME: 20-30 minutes")
    print("üî• 4x V100 GPUs (64GB GPU RAM)")
    print("üß† IoT MODEL: 1M+ parameters")
    print("üìä TRAINING DATA: Synthetic IoT samples")
    print("üéØ PREDICTIVE LEAD TIMES: Minutes to Weeks")
    print("üî•" * 60)

def run_cmd(cmd, description=""):
    """Run command with detailed error reporting."""
    print(f"üîß {description}")
    print(f"   Command: {cmd}")
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            print(f"   ‚úÖ Success")
            if result.stdout.strip():
                output_preview = result.stdout.strip()[:200]
                print(f"   Output: {output_preview}...")
            return True, result.stdout
        else:
            print(f"   ‚ùå Failed (exit code: {result.returncode})")
            if result.stderr.strip():
                print(f"   Error: {result.stderr.strip()}")
            return False, result.stderr
            
    except subprocess.TimeoutExpired:
        print(f"   ‚è∞ Timeout after 120 seconds")
        return False, "Timeout"
    except Exception as e:
        print(f"   üí• Exception: {e}")
        return False, str(e)

def upload_fixed_training_code(bucket_name):
    """Upload fixed training code to S3."""
    print("üì§ Uploading FIXED training code to S3...")
    
    # Create simplified, robust training script
    training_script = '''#!/usr/bin/env python3
"""
Simplified SageMaker IoT Fire Detection Training Script
"""

import os
import sys
import json
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from datetime import datetime
import argparse

print("üî• Starting FIXED IoT Fire Detection Training!")
print(f"Python version: {sys.version}")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPU count: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")

# Simple IoT Model Configuration
class SimpleIoTConfig:
    def __init__(self):
        self.num_areas = 5
        self.area_features = [1, 1, 2, 1, 3]  # Kitchen, Electrical, HVAC, Living, Basement
        self.d_model = 128  # Smaller for stability
        self.num_heads = 4
        self.num_layers = 3
        self.seq_len = 60
        self.dropout = 0.1
        self.num_risk_levels = 4

# Simplified IoT Fire Detection Model
class SimpleIoTModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # Simple embeddings for each area
        self.embeddings = nn.ModuleList([
            nn.Linear(feat_dim, config.d_model) 
            for feat_dim in config.area_features
        ])
        
        # Simple transformer
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=config.d_model,
                nhead=config.num_heads,
                dim_feedforward=config.d_model * 2,
                dropout=config.dropout,
                batch_first=True
            ),
            num_layers=config.num_layers
        )
        
        # Output heads
        self.lead_time_head = nn.Linear(config.d_model, config.num_risk_levels)
        self.area_risk_head = nn.Linear(config.d_model, config.num_areas)
        self.time_regression_head = nn.Linear(config.d_model, 1)
    
    def forward(self, x):
        # x shape: (batch_size, seq_len, total_features)
        batch_size, seq_len = x.shape[:2]
        
        # Split features by area
        features_split = []
        start_idx = 0
        
        for i, feat_dim in enumerate(self.config.area_features):
            end_idx = start_idx + feat_dim
            area_features = x[:, :, start_idx:end_idx]
            embedded = self.embeddings[i](area_features)
            features_split.append(embedded)
            start_idx = end_idx
        
        # Combine all areas: (batch_size, seq_len * num_areas, d_model)
        combined = torch.cat(features_split, dim=1)
        
        # Apply transformer
        transformed = self.transformer(combined)
        
        # Global pooling
        pooled = transformed.mean(dim=1)  # (batch_size, d_model)
        
        # Predictions
        lead_time_logits = self.lead_time_head(pooled)
        area_risks = torch.sigmoid(self.area_risk_head(pooled))
        time_to_ignition = torch.relu(self.time_regression_head(pooled))
        
        return {
            'lead_time_logits': lead_time_logits,
            'area_risks': area_risks,
            'time_to_ignition': time_to_ignition
        }

def generate_simple_data(num_samples=10000, seq_len=60):
    """Generate simple synthetic data."""
    print(f"Generating {num_samples} synthetic samples...")
    
    # Total features: 1+1+2+1+3 = 8
    total_features = 8
    data = torch.randn(num_samples, seq_len, total_features)
    
    # Generate labels
    lead_time_labels = torch.randint(0, 4, (num_samples,))
    area_risk_labels = torch.rand(num_samples, 5)
    time_labels = torch.rand(num_samples, 1) * 100  # 0-100 hours
    
    return data, lead_time_labels, area_risk_labels, time_labels

def train_model():
    """Main training function."""
    
    # Parse arguments
    parser = argparse.ArgumentParser()
    parser.add_argument('--epochs', type=int, default=50)
    parser.add_argument('--batch-size', type=int, default=128)
    parser.add_argument('--learning-rate', type=float, default=0.001)
    args = parser.parse_args()
    
    print(f"Training parameters:")
    print(f"  Epochs: {args.epochs}")
    print(f"  Batch size: {args.batch_size}")
    print(f"  Learning rate: {args.learning_rate}")
    
    # Setup device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # Create model
    config = SimpleIoTConfig()
    model = SimpleIoTModel(config).to(device)
    
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # Generate data
    data, lead_time_labels, area_risk_labels, time_labels = generate_simple_data(20000)
    
    # Move to device
    data = data.to(device)
    lead_time_labels = lead_time_labels.to(device)
    area_risk_labels = area_risk_labels.to(device)
    time_labels = time_labels.to(device)
    
    # Training setup
    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)
    
    lead_time_criterion = nn.CrossEntropyLoss()
    area_risk_criterion = nn.MSELoss()
    time_criterion = nn.MSELoss()
    
    # Training loop
    model.train()
    batch_size = args.batch_size
    num_samples = data.shape[0]
    
    print(f"Starting training: {args.epochs} epochs, {num_samples} samples")
    
    for epoch in range(args.epochs):
        epoch_loss = 0.0
        num_batches = 0
        
        for start_idx in range(0, num_samples, batch_size):
            end_idx = min(start_idx + batch_size, num_samples)
            
            # Get batch
            batch_data = data[start_idx:end_idx]
            batch_lead_time = lead_time_labels[start_idx:end_idx]
            batch_area_risks = area_risk_labels[start_idx:end_idx]
            batch_time = time_labels[start_idx:end_idx]
            
            # Forward pass
            optimizer.zero_grad()
            outputs = model(batch_data)
            
            # Calculate losses
            lead_loss = lead_time_criterion(outputs['lead_time_logits'], batch_lead_time)
            area_loss = area_risk_criterion(outputs['area_risks'], batch_area_risks)
            time_loss = time_criterion(outputs['time_to_ignition'], batch_time)
            
            total_loss = lead_loss + 0.5 * area_loss + 0.3 * time_loss
            
            # Backward pass
            total_loss.backward()
            optimizer.step()
            
            epoch_loss += total_loss.item()
            num_batches += 1
        
        if (epoch + 1) % 10 == 0:
            avg_loss = epoch_loss / num_batches
            print(f"Epoch {epoch+1}/{args.epochs}: Loss = {avg_loss:.4f}")
    
    # Save model
    model_dir = os.environ.get('SM_MODEL_DIR', '/opt/ml/model')
    os.makedirs(model_dir, exist_ok=True)
    
    # Save model state
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config.__dict__,
        'final_loss': epoch_loss / num_batches,
        'epochs': args.epochs,
        'samples': num_samples,
        'timestamp': datetime.now().isoformat()
    }, os.path.join(model_dir, 'iot_model.pth'))
    
    # Save metrics
    metrics = {
        'final_loss': float(epoch_loss / num_batches),
        'epochs': args.epochs,
        'training_samples': num_samples,
        'model_parameters': sum(p.numel() for p in model.parameters()),
        'device': str(device),
        'success': True
    }
    
    with open(os.path.join(model_dir, 'metrics.json'), 'w') as f:
        json.dump(metrics, f, indent=2)
    
    print("‚úÖ Training completed successfully!")
    print(f"Final loss: {epoch_loss / num_batches:.4f}")
    print(f"Model saved to: {model_dir}")

if __name__ == "__main__":
    try:
        train_model()
    except Exception as e:
        print(f"‚ùå Training failed with error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
'''
    
    # Save training script
    with open('iot_train_fixed.py', 'w') as f:
        f.write(training_script)
    
    # Upload to S3
    s3_code_path = f"s3://{bucket_name}/code/iot_train_fixed.py"
    success, _ = run_cmd(f"aws s3 cp iot_train_fixed.py {s3_code_path}", "Uploading FIXED training script")
    
    if success:
        print(f"   ‚úÖ FIXED training script uploaded to: {s3_code_path}")
    
    # Cleanup local file
    if os.path.exists('iot_train_fixed.py'):
        os.remove('iot_train_fixed.py')
    
    return s3_code_path

def create_fixed_training_job(account_id, region, role_arn, bucket_name):
    """Create fixed SageMaker training job."""
    print("üöÄ Creating FIXED IoT Training Job...")
    
    job_name = f"saafe-iot-fixed-{int(time.time())}"
    
    # Use PyTorch container
    image_uri = f"763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:1.13.1-gpu-py39-cu117-ubuntu20.04-sagemaker"
    
    training_job = {
        "TrainingJobName": job_name,
        "RoleArn": role_arn,
        "AlgorithmSpecification": {
            "TrainingImage": image_uri,
            "TrainingInputMode": "File"
        },
        "InputDataConfig": [
            {
                "ChannelName": "code",
                "DataSource": {
                    "S3DataSource": {
                        "S3DataType": "S3Prefix",
                        "S3Uri": f"s3://{bucket_name}/code/",
                        "S3DataDistributionType": "FullyReplicated"
                    }
                }
            }
        ],
        "OutputDataConfig": {
            "S3OutputPath": f"s3://{bucket_name}/output/"
        },
        "ResourceConfig": {
            "InstanceType": "ml.p3.8xlarge",  # 4x V100 GPUs
            "InstanceCount": 1,
            "VolumeSizeInGB": 50
        },
        "StoppingCondition": {
            "MaxRuntimeInSeconds": 3600  # 1 hour max
        },
        "HyperParameters": {
            "epochs": "50",
            "batch-size": "128",
            "learning-rate": "0.001"
        },
        "Environment": {
            "SAGEMAKER_PROGRAM": "iot_train_fixed.py"
        }
    }
    
    # Save job definition
    with open('iot_training_job_fixed.json', 'w') as f:
        json.dump(training_job, f, indent=2)
    
    print(f"   Job name: {job_name}")
    print(f"   Instance: ml.p3.8xlarge (4x V100 GPUs)")
    print(f"   Estimated cost: $6-10")
    print(f"   Expected time: 20-30 minutes")
    
    # Create training job
    success, output = run_cmd(f"aws sagemaker create-training-job --cli-input-json file://iot_training_job_fixed.json", "Creating FIXED training job")
    
    if success:
        print("‚úÖ FIXED IoT Training job created successfully!")
        print(f"üîç Monitor at: https://{region}.console.aws.amazon.com/sagemaker/home?region={region}#/jobs")
        return job_name
    else:
        print("‚ùå Training job creation failed")
        print(f"Error: {output}")
        return None

def monitor_training_job(job_name, region):
    """Monitor training job progress."""
    print(f"‚è≥ Monitoring training job: {job_name}")
    print("Press Ctrl+C to stop monitoring (training will continue)")
    
    try:
        while True:
            success, status_output = run_cmd(f"aws sagemaker describe-training-job --training-job-name {job_name} --query TrainingJobStatus --output text", "Checking status")
            
            if success:
                status = status_output.strip()
                timestamp = datetime.now().strftime("%H:%M:%S")
                print(f"   [{timestamp}] Status: {status}")
                
                if status == 'Completed':
                    print("üéâ Training completed successfully!")
                    
                    # Get output location
                    success, output_info = run_cmd(f"aws sagemaker describe-training-job --training-job-name {job_name} --query OutputDataConfig.S3OutputPath --output text", "Getting output location")
                    if success:
                        output_path = output_info.strip()
                        print(f"üìÅ Model artifacts: {output_path}")
                        print(f"üíæ Download with: aws s3 sync {output_path} ./trained_models/")
                    
                    break
                elif status == 'Failed':
                    print("‚ùå Training failed!")
                    break
                elif status == 'Stopping' or status == 'Stopped':
                    print("‚èπÔ∏è Training stopped")
                    break
            
            time.sleep(30)  # Check every 30 seconds
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Monitoring stopped (training continues in background)")

def main():
    """Main function for fixed AWS IoT training."""
    print_banner()
    
    # Use existing resources
    account_id = "691595239825"
    region = "us-east-1"
    role_arn = f"arn:aws:iam::{account_id}:role/SaafeIoTTrainingRole"
    bucket_name = f"saafe-iot-training-{account_id}-{region}"
    
    print(f"‚úÖ Using existing AWS resources:")
    print(f"   Account: {account_id}")
    print(f"   Region: {region}")
    print(f"   Role: SaafeIoTTrainingRole")
    print(f"   Bucket: {bucket_name}")
    
    # Upload fixed training code
    upload_fixed_training_code(bucket_name)
    
    # Confirm launch
    print("\nüî• FIXED IoT TRAINING CONFIGURATION")
    print("=" * 40)
    print("Model: Simplified IoT Fire Detection")
    print("Instance: ml.p3.8xlarge (4x V100 GPUs)")
    print("Training: 20K synthetic samples, 50 epochs")
    print("Features: 5 areas, simplified architecture")
    print("Cost: ~$12.24/hour")
    print("Expected time: 20-30 minutes")
    print("Expected total: $4.00-6.00")
    print()
    
    confirm = input("üöÄ Launch FIXED IoT training? (y/N): ").strip().lower()
    if confirm != 'y':
        print("üëç Training cancelled")
        return
    
    # Create and launch training job
    job_name = create_fixed_training_job(account_id, region, role_arn, bucket_name)
    
    if job_name:
        print(f"\nüéâ SUCCESS!")
        print(f"=" * 30)
        print(f"‚úÖ FIXED IoT training job launched: {job_name}")
        print(f"‚è±Ô∏è Expected completion: 20-30 minutes")
        print(f"üí∞ Expected cost: $4.00-6.00")
        
        # Monitor
        monitor = input("\nüìä Monitor training progress? (y/N): ").strip().lower()
        if monitor == 'y':
            monitor_training_job(job_name, region)
    
    # Cleanup
    for f in ['iot_training_job_fixed.json']:
        if os.path.exists(f):
            os.remove(f)

if __name__ == "__main__":
    main()